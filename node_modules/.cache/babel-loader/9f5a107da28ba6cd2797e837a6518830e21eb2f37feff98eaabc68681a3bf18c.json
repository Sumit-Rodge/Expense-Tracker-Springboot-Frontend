{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.OrderedBulkOperation = void 0;\nconst BSON = require(\"../bson\");\nconst error_1 = require(\"../error\");\nconst common_1 = require(\"./common\");\n/** @public */\nclass OrderedBulkOperation extends common_1.BulkOperationBase {\n  /** @internal */\n  constructor(collection, options) {\n    super(collection, options, true);\n  }\n  addToOperationsList(batchType, document) {\n    // Get the bsonSize\n    const bsonSize = BSON.calculateObjectSize(document, {\n      checkKeys: false,\n      // Since we don't know what the user selected for BSON options here,\n      // err on the safe side, and check the size with ignoreUndefined: false.\n      ignoreUndefined: false\n    });\n    // Throw error if the doc is bigger than the max BSON size\n    if (bsonSize >= this.s.maxBsonObjectSize)\n      // TODO(NODE-3483): Change this to MongoBSONError\n      throw new error_1.MongoInvalidArgumentError(`Document is larger than the maximum size ${this.s.maxBsonObjectSize}`);\n    // Create a new batch object if we don't have a current one\n    if (this.s.currentBatch == null) {\n      this.s.currentBatch = new common_1.Batch(batchType, this.s.currentIndex);\n    }\n    const maxKeySize = this.s.maxKeySize;\n    // Check if we need to create a new batch\n    if (\n    // New batch if we exceed the max batch op size\n    this.s.currentBatchSize + 1 >= this.s.maxWriteBatchSize ||\n    // New batch if we exceed the maxBatchSizeBytes. Only matters if batch already has a doc,\n    // since we can't sent an empty batch\n    this.s.currentBatchSize > 0 && this.s.currentBatchSizeBytes + maxKeySize + bsonSize >= this.s.maxBatchSizeBytes ||\n    // New batch if the new op does not have the same op type as the current batch\n    this.s.currentBatch.batchType !== batchType) {\n      // Save the batch to the execution stack\n      this.s.batches.push(this.s.currentBatch);\n      // Create a new batch\n      this.s.currentBatch = new common_1.Batch(batchType, this.s.currentIndex);\n      // Reset the current size trackers\n      this.s.currentBatchSize = 0;\n      this.s.currentBatchSizeBytes = 0;\n    }\n    if (batchType === common_1.BatchType.INSERT) {\n      this.s.bulkResult.insertedIds.push({\n        index: this.s.currentIndex,\n        _id: document._id\n      });\n    }\n    // We have an array of documents\n    if (Array.isArray(document)) {\n      throw new error_1.MongoInvalidArgumentError('Operation passed in cannot be an Array');\n    }\n    this.s.currentBatch.originalIndexes.push(this.s.currentIndex);\n    this.s.currentBatch.operations.push(document);\n    this.s.currentBatchSize += 1;\n    this.s.currentBatchSizeBytes += maxKeySize + bsonSize;\n    this.s.currentIndex += 1;\n    return this;\n  }\n}\nexports.OrderedBulkOperation = OrderedBulkOperation;","map":{"version":3,"names":["BSON","require","error_1","common_1","OrderedBulkOperation","BulkOperationBase","constructor","collection","options","addToOperationsList","batchType","document","bsonSize","calculateObjectSize","checkKeys","ignoreUndefined","s","maxBsonObjectSize","MongoInvalidArgumentError","currentBatch","Batch","currentIndex","maxKeySize","currentBatchSize","maxWriteBatchSize","currentBatchSizeBytes","maxBatchSizeBytes","batches","push","BatchType","INSERT","bulkResult","insertedIds","index","_id","Array","isArray","originalIndexes","operations","exports"],"sources":["C:\\Users\\sumit\\Desktop\\Final project\\Expense-Tracker-Springboot-Frontend\\node_modules\\mongodb\\src\\bulk\\ordered.ts"],"sourcesContent":["import type { Document } from '../bson';\r\nimport * as BSON from '../bson';\r\nimport type { Collection } from '../collection';\r\nimport { MongoInvalidArgumentError } from '../error';\r\nimport type { DeleteStatement } from '../operations/delete';\r\nimport type { UpdateStatement } from '../operations/update';\r\nimport { Batch, BatchType, BulkOperationBase, type BulkWriteOptions } from './common';\r\n\r\n/** @public */\r\nexport class OrderedBulkOperation extends BulkOperationBase {\r\n  /** @internal */\r\n  constructor(collection: Collection, options: BulkWriteOptions) {\r\n    super(collection, options, true);\r\n  }\r\n\r\n  addToOperationsList(\r\n    batchType: BatchType,\r\n    document: Document | UpdateStatement | DeleteStatement\r\n  ): this {\r\n    // Get the bsonSize\r\n    const bsonSize = BSON.calculateObjectSize(document, {\r\n      checkKeys: false,\r\n      // Since we don't know what the user selected for BSON options here,\r\n      // err on the safe side, and check the size with ignoreUndefined: false.\r\n      ignoreUndefined: false\r\n    } as any);\r\n\r\n    // Throw error if the doc is bigger than the max BSON size\r\n    if (bsonSize >= this.s.maxBsonObjectSize)\r\n      // TODO(NODE-3483): Change this to MongoBSONError\r\n      throw new MongoInvalidArgumentError(\r\n        `Document is larger than the maximum size ${this.s.maxBsonObjectSize}`\r\n      );\r\n\r\n    // Create a new batch object if we don't have a current one\r\n    if (this.s.currentBatch == null) {\r\n      this.s.currentBatch = new Batch(batchType, this.s.currentIndex);\r\n    }\r\n\r\n    const maxKeySize = this.s.maxKeySize;\r\n\r\n    // Check if we need to create a new batch\r\n    if (\r\n      // New batch if we exceed the max batch op size\r\n      this.s.currentBatchSize + 1 >= this.s.maxWriteBatchSize ||\r\n      // New batch if we exceed the maxBatchSizeBytes. Only matters if batch already has a doc,\r\n      // since we can't sent an empty batch\r\n      (this.s.currentBatchSize > 0 &&\r\n        this.s.currentBatchSizeBytes + maxKeySize + bsonSize >= this.s.maxBatchSizeBytes) ||\r\n      // New batch if the new op does not have the same op type as the current batch\r\n      this.s.currentBatch.batchType !== batchType\r\n    ) {\r\n      // Save the batch to the execution stack\r\n      this.s.batches.push(this.s.currentBatch);\r\n\r\n      // Create a new batch\r\n      this.s.currentBatch = new Batch(batchType, this.s.currentIndex);\r\n\r\n      // Reset the current size trackers\r\n      this.s.currentBatchSize = 0;\r\n      this.s.currentBatchSizeBytes = 0;\r\n    }\r\n\r\n    if (batchType === BatchType.INSERT) {\r\n      this.s.bulkResult.insertedIds.push({\r\n        index: this.s.currentIndex,\r\n        _id: (document as Document)._id\r\n      });\r\n    }\r\n\r\n    // We have an array of documents\r\n    if (Array.isArray(document)) {\r\n      throw new MongoInvalidArgumentError('Operation passed in cannot be an Array');\r\n    }\r\n\r\n    this.s.currentBatch.originalIndexes.push(this.s.currentIndex);\r\n    this.s.currentBatch.operations.push(document);\r\n    this.s.currentBatchSize += 1;\r\n    this.s.currentBatchSizeBytes += maxKeySize + bsonSize;\r\n    this.s.currentIndex += 1;\r\n    return this;\r\n  }\r\n}\r\n"],"mappings":";;;;;;AACA,MAAAA,IAAA,GAAAC,OAAA;AAEA,MAAAC,OAAA,GAAAD,OAAA;AAGA,MAAAE,QAAA,GAAAF,OAAA;AAEA;AACA,MAAaG,oBAAqB,SAAQD,QAAA,CAAAE,iBAAiB;EACzD;EACAC,YAAYC,UAAsB,EAAEC,OAAyB;IAC3D,KAAK,CAACD,UAAU,EAAEC,OAAO,EAAE,IAAI,CAAC;EAClC;EAEAC,mBAAmBA,CACjBC,SAAoB,EACpBC,QAAsD;IAEtD;IACA,MAAMC,QAAQ,GAAGZ,IAAI,CAACa,mBAAmB,CAACF,QAAQ,EAAE;MAClDG,SAAS,EAAE,KAAK;MAChB;MACA;MACAC,eAAe,EAAE;KACX,CAAC;IAET;IACA,IAAIH,QAAQ,IAAI,IAAI,CAACI,CAAC,CAACC,iBAAiB;MACtC;MACA,MAAM,IAAIf,OAAA,CAAAgB,yBAAyB,CACjC,4CAA4C,IAAI,CAACF,CAAC,CAACC,iBAAiB,EAAE,CACvE;IAEH;IACA,IAAI,IAAI,CAACD,CAAC,CAACG,YAAY,IAAI,IAAI,EAAE;MAC/B,IAAI,CAACH,CAAC,CAACG,YAAY,GAAG,IAAIhB,QAAA,CAAAiB,KAAK,CAACV,SAAS,EAAE,IAAI,CAACM,CAAC,CAACK,YAAY,CAAC;;IAGjE,MAAMC,UAAU,GAAG,IAAI,CAACN,CAAC,CAACM,UAAU;IAEpC;IACA;IACE;IACA,IAAI,CAACN,CAAC,CAACO,gBAAgB,GAAG,CAAC,IAAI,IAAI,CAACP,CAAC,CAACQ,iBAAiB;IACvD;IACA;IACC,IAAI,CAACR,CAAC,CAACO,gBAAgB,GAAG,CAAC,IAC1B,IAAI,CAACP,CAAC,CAACS,qBAAqB,GAAGH,UAAU,GAAGV,QAAQ,IAAI,IAAI,CAACI,CAAC,CAACU,iBAAkB;IACnF;IACA,IAAI,CAACV,CAAC,CAACG,YAAY,CAACT,SAAS,KAAKA,SAAS,EAC3C;MACA;MACA,IAAI,CAACM,CAAC,CAACW,OAAO,CAACC,IAAI,CAAC,IAAI,CAACZ,CAAC,CAACG,YAAY,CAAC;MAExC;MACA,IAAI,CAACH,CAAC,CAACG,YAAY,GAAG,IAAIhB,QAAA,CAAAiB,KAAK,CAACV,SAAS,EAAE,IAAI,CAACM,CAAC,CAACK,YAAY,CAAC;MAE/D;MACA,IAAI,CAACL,CAAC,CAACO,gBAAgB,GAAG,CAAC;MAC3B,IAAI,CAACP,CAAC,CAACS,qBAAqB,GAAG,CAAC;;IAGlC,IAAIf,SAAS,KAAKP,QAAA,CAAA0B,SAAS,CAACC,MAAM,EAAE;MAClC,IAAI,CAACd,CAAC,CAACe,UAAU,CAACC,WAAW,CAACJ,IAAI,CAAC;QACjCK,KAAK,EAAE,IAAI,CAACjB,CAAC,CAACK,YAAY;QAC1Ba,GAAG,EAAGvB,QAAqB,CAACuB;OAC7B,CAAC;;IAGJ;IACA,IAAIC,KAAK,CAACC,OAAO,CAACzB,QAAQ,CAAC,EAAE;MAC3B,MAAM,IAAIT,OAAA,CAAAgB,yBAAyB,CAAC,wCAAwC,CAAC;;IAG/E,IAAI,CAACF,CAAC,CAACG,YAAY,CAACkB,eAAe,CAACT,IAAI,CAAC,IAAI,CAACZ,CAAC,CAACK,YAAY,CAAC;IAC7D,IAAI,CAACL,CAAC,CAACG,YAAY,CAACmB,UAAU,CAACV,IAAI,CAACjB,QAAQ,CAAC;IAC7C,IAAI,CAACK,CAAC,CAACO,gBAAgB,IAAI,CAAC;IAC5B,IAAI,CAACP,CAAC,CAACS,qBAAqB,IAAIH,UAAU,GAAGV,QAAQ;IACrD,IAAI,CAACI,CAAC,CAACK,YAAY,IAAI,CAAC;IACxB,OAAO,IAAI;EACb;;AAxEFkB,OAAA,CAAAnC,oBAAA,GAAAA,oBAAA","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}